## IONathon 1.0 (Prototype Phase)

# Theme: Social service / (focused on underprivileged only)

# Team Name: 
## arnav0929

# Project Name:
## God's Eye

![photo_2022-03-26_03-15-10](https://user-images.githubusercontent.com/73690811/160207334-b364c377-c9cf-4186-84c6-8de8132e0629.jpg)

# Solution:
AI-based spectacles that will tell blind people about their surroundings in real-time.

# Features:
1) It will assist visually impaired person in navigating from one place to another.
2) It will have OCR technology which will help the visually impaired person to read books and newspapers.
3) The facial recognition module will help the visually impaired person to know the person sitting in front of him/her.

# Working:
![Methodology](https://user-images.githubusercontent.com/73690811/160275683-16184713-08c2-4a5c-b63b-46d872144097.png)

# Architecture:
Create a multimodal neural network that uses feature vectors obtained using both RNN and CNN, so consequently, two inputs have to be taken.
One is the image we need to describe, a feed to the CNN, and the second is the words in the text sequence produced till now as a sequence as the input to the RNN.
#

![Arnav-01](https://user-images.githubusercontent.com/73690811/160275549-182cb6fa-22ff-49da-af27-9cf341b9bb09.jpg)
#
# Instructions to run God's Eye ?
Step 1: Download the repository as zipped file
Step 2: Extract zip
Step 3: Install dependencies from requirements.txt
Step 4: Run main.py 
Step 5: Web Cam will start working. We have 3 Modes, Initially Live-environment captioning module will work (Mode 1, press 1 to start this mode), enter 2 to start Facial Recognition mode and enter 3 to start Optical Character Recognition Mode (i.e enter 1, 2 or 3 to switch between modes)
Step 6: Enter ESC button to end 
